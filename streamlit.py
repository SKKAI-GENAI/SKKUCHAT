import streamlit as st
from konlpy.tag import Okt
from dotenv import load_dotenv
import os
import openai
from retrieval import SparseRetrieval
import subprocess
import json

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# Streamlit ì„¤ì •
st.set_page_config(page_title="ìŠ¤ê¾¸ì±— - ì„±ê· ê´€ëŒ€ ì±—ë´‡", page_icon="ğŸ¤–")
st.title("ğŸ¦ ìŠ¤ê¾¸ì±—: ì„±ê· ê´€ëŒ€ ê³µì§€ì‚¬í•­ ì±—ë´‡")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat" not in st.session_state:
    st.session_state["chat"] = []

# Retriever ìºì‹œë¡œ ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_resource
def load_retriever():
    try:
        subprocess.run(["python3", "crawl_notice.py"], check=True)
    except subprocess.CalledProcessError as e:
        print(f"Error while running crawl_notice.py: {e}")
        return []
    try:
        with open("skku_notices.json", "r", encoding="utf-8") as f:
            notices = json.load(f)
    except FileNotFoundError:
        print("skku_notices.json not found.")
        return []
    except json.JSONDecodeError as e:
        print(f"Error decoding skku_notices.json: {e}")
        return []

    retriever = SparseRetrieval(tokenize_fn=Okt().morphs, context_path="skku_notices.json")
    retriever.get_sparse_embedding()
    return retriever

retriever = load_retriever()

# ì²« ì¸ì‚¿ë§
if not st.session_state["chat"]:
    with st.chat_message("assistant"):
        st.write("ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì„±ê· ê´€ëŒ€í•™êµ ê³µì§€ì‚¬í•­ ì±—ë´‡, ìŠ¤ê¾¸ì±—ì…ë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!")

# ê¸°ì¡´ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶œë ¥
for role, msg in st.session_state["chat"]:
    with st.chat_message(role):
        st.write(msg)

# ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
prompt = st.chat_input("ì„±ê· ê´€ëŒ€ ê´€ë ¨ ê¶ê¸ˆí•œ ê³µì§€ë¥¼ ì…ë ¥í•´ë³´ì„¸ìš”!")

if prompt:
    # ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ê°€
    st.session_state["chat"].append(("user", prompt))
    st.chat_message("user").write(prompt)

    # ê´€ë ¨ ê³µì§€ ì¶”ì¶œ
    scores, notice_ids = retriever.retrieve(prompt, topk=3)
    title_url_pairs = []
    for nid in notice_ids:
        idx = retriever.notice_ids.index(nid)
        title = retriever.titles[idx]
        url = f"https://www.skku.edu/skku/campus/skk_comm/notice01.do?mode=view&articleNo={int(nid)}"
        title_url_pairs.append((title, url))
    title_url_text = "\n".join([f"{i+1}. {title} {url}" for i, (title, url) in enumerate(title_url_pairs)])

    with st.chat_message("assistant"):
        st.write("ğŸ” ê´€ë ¨ ê³µì§€ë¥¼ ì°¾ì•˜ì–´ìš”:\n")
        st.write(title_url_text)
        st.write(scores)

    st.session_state["chat"].append(("assistant", "ğŸ” ê´€ë ¨ ê³µì§€ë¥¼ ì°¾ì•˜ì–´ìš”:\n" + title_url_text))

    # GPT ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            context_docs = [retriever.contexts[retriever.notice_ids.index(nid)] for nid in notice_ids]
            joined_context = "\n\n".join(context_docs)
            full_prompt = f"""ì•„ë˜ëŠ” ì„±ê· ê´€ëŒ€í•™êµ ê³µì§€ì‚¬í•­ ì¤‘ ê´€ë ¨ëœ ë‚´ìš©ì…ë‹ˆë‹¤:\n\n{joined_context}\n\nì‚¬ìš©ìì˜ ì§ˆë¬¸: "{prompt}"\n\nìœ„ ê³µì§€ë¥¼ ì°¸ê³ í•˜ì—¬ ì •ë¦¬ëœ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."""
            try:
                response = openai.ChatCompletion.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": full_prompt}],
                    temperature=0.5,
                )
                answer = response["choices"][0]["message"]["content"].strip()
            except Exception as e:
                answer = f"â—ï¸OpenAI API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}"
            st.write(answer)
            st.session_state["chat"].append(("assistant", answer))

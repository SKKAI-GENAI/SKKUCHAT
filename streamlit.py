import streamlit as st

from dotenv import load_dotenv
from utils.Crawler import Crawler

from openai import OpenAI
from retrieval import SparseRetrieval

load_dotenv()

st.set_page_config(page_title="SKKUCHAT", page_icon="ğŸ¤–")
st.title("ğŸ¤– SKKUCHAT(ìŠ¤ê¾¸ì±—)")
st.subheader("ã…¤ã…¤ì„±ê· ê´€ëŒ€ ê³µì§€ì‚¬í•­ ì±—ë´‡")
st.write("")


@st.cache_resource(show_spinner="ì±—ë´‡ ë¡œë”©ì¤‘...")
def load_retriever():
    Crawler(max_pages=100)
    retriever = SparseRetrieval()
    return retriever

retriever = load_retriever()

# ëŒ€í™” ê¸°ë¡
if "chat" not in st.session_state:
    st.session_state["chat"] = [
        (
            "assistant",
            "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì„±ê· ê´€ëŒ€í•™êµ ê³µì§€ì‚¬í•­ ì±—ë´‡, ìŠ¤ê¾¸ì±—ì…ë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!",
        ) # ì²« ì¸ì‚¿ë§
    ]

# ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
for role, msg in st.session_state["chat"]:
    with st.chat_message(role):
        st.write(msg)

# ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
prompt = st.chat_input("ì„±ê· ê´€ëŒ€ ê³µì§€ì‚¬í•­ ê´€ë ¨ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!")

if prompt:
    # ëŒ€í™” ê¸°ë¡ì— ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ê°€
    st.chat_message("user").write(prompt)
    st.session_state["chat"].append(("user", prompt))

    # ê´€ë ¨ ê³µì§€ ê²€ìƒ‰
    with st.spinner("ê´€ë ¨ ê³µì§€ì‚¬í•­ íƒìƒ‰ ì¤‘..."):
        results = retriever.retrieve(prompt, topk=3)

    if not results:
        with st.chat_message("assistant"):
            st.write("â—ï¸ ê´€ë ¨ ê³µì§€ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. ì•„ë˜ì™€ ê°™ì€ ê²½ìš° ê³µì§€ì‚¬í•­ì„ ì œëŒ€ë¡œ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”.")
            st.write("1. ì…ë ¥ëœ ì§ˆë¬¸ì´ ë¹„ì–´ìˆì–´ìš”.")
            st.write("2. ì§ˆë¬¸ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ëª…í™•í•˜ì§€ ì•Šì•„ìš”.")
            st.write("3. ë„ˆë¬´ í¬ê´„ì ì¸ ì§ˆë¬¸ì´ì—ìš”. ì¡°ê¸ˆ ë” ìì„¸í•˜ê²Œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”!")
            st.write("4. ì„±ê· ê´€ëŒ€í•™êµ ê³µì§€ì‚¬í•­ê³¼ ë¬´ê´€í•œ ì§ˆë¬¸ì´ì—ìš”.")
        st.session_state["chat"].append(("assistant", "â—ï¸ ê´€ë ¨ ê³µì§€ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. ì•„ë˜ì™€ ê°™ì€ ê²½ìš° ê³µì§€ì‚¬í•­ì„ ì œëŒ€ë¡œ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”:\n1. ì…ë ¥ëœ ì§ˆë¬¸ì´ ë¹„ì–´ìˆì–´ìš”.\n2. ì§ˆë¬¸ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ëª…í™•í•˜ì§€ ì•Šì•„ìš”.\n3. ë„ˆë¬´ í¬ê´„ì ì¸ ì§ˆë¬¸ì´ì—ìš”. ì¡°ê¸ˆ ë” ìì„¸í•˜ê²Œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”!\n4. ì„±ê· ê´€ëŒ€í•™êµ ê³µì§€ì‚¬í•­ê³¼ ë¬´ê´€í•œ ì§ˆë¬¸ì´ì—ìš”."))
    else:
        notice_links = []
        for _, notice_info in results:
            title = notice_info["title"]
            url = f"https://www.skku.edu/skku/campus/skk_comm/notice01.do?mode=view&articleNo={notice_info["id"]}"
            notice_links.append((title, url))
        notice_text = "\n".join([f"{i+1}. {title} {url}" for i, (title, url) in enumerate(notice_links)])

        with st.chat_message("assistant"):
            st.write("ğŸ” ê´€ë ¨ ê³µì§€ë¥¼ ì°¾ì•˜ì–´ìš”:")
            st.write(notice_text)
            st.write([logit for logit, _ in results])
        st.session_state["chat"].append(("assistant", "ğŸ” ê´€ë ¨ ê³µì§€ë¥¼ ì°¾ì•˜ì–´ìš”:\n" + notice_text))

        # GPT ì‘ë‹µ ìƒì„±
        with st.spinner("ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± ì¤‘..."):
            context = [notice_info["content"] + "\n\n" for _, notice_info in results]
            full_prompt = f"""ì•„ë˜ëŠ” ì„±ê· ê´€ëŒ€í•™êµ ê³µì§€ì‚¬í•­ ì¤‘ ê´€ë ¨ëœ ë‚´ìš©ì…ë‹ˆë‹¤:\n\n{context}\n\nì‚¬ìš©ìì˜ ì§ˆë¬¸: "{prompt}"\n\nìœ„ ê³µì§€ë¥¼ ì°¸ê³ í•˜ì—¬ ì •ë¦¬ëœ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."""

            try:
                client = OpenAI()
                response = client.responses.create(
                    model="gpt-4o-mini",
                    input=[{"role": "user", "content": full_prompt}],
                    temperature=0.5,
                )
                response = response.output_text
            except Exception as e:
                response = f"â—ï¸OpenAI API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}"

            st.chat_message("assistant").write(response)
            st.session_state["chat"].append(("assistant", response))
